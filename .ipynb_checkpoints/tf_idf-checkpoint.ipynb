{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d986601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28765b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    " \n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    " \n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d79ef8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cut_content</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#上海疫情##上海民生##就这一刻##返乡# 上海返乡潮开启，安徽、江苏和河南人最多，隔离和...</td>\n",
       "      <td>2022-04-24</td>\n",
       "      <td>2022-04-24 08:33:43</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 疫情 ## 上海 民生 ## 就 这 一刻 ## 返乡 #   上海 返乡 潮 开...</td>\n",
       "      <td>疫情 民生 一刻 返乡   返乡 潮 开启 安徽 江苏 河南人 隔离 做 核酸 钱 返乡 潮...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#上海疫情##上海民生##上海现状# .上海的现状为什么会变成这样我忍不住地继续瞎想外行领导...</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2022-04-23 05:46:14</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 疫情 ## 上海 民生 ## 上海 现状 #   . 上海 的 现状 为什么 会 ...</td>\n",
       "      <td>疫情 民生 现状   现状 忍不住 瞎 想 外行 领导 内行 内行 闭嘴 同理 衍生 行业 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#上海疫情##上海民生#      无间道，罗生门，可能本来就是人生如戏吧，是我太认真了。算...</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>2022-04-22 11:47:31</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 疫情 ## 上海 民生 #             无间道 ， 罗生门 ， 可能 ...</td>\n",
       "      <td>疫情 民生             无间道 罗生门 本来 人生 如戏 是我太 算了 干脆 眼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#上海民生##上海疫情##上海团长# 还是你牛逼呀，团长。开个车照送，还是封控小区。</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>2022-04-22 09:41:33</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 民生 ## 上海 疫情 ## 上海 团长 #   还是 你 牛 逼 呀 ， 团长 ...</td>\n",
       "      <td>民生 疫情 团长   牛 逼 团长 开个 车照 送 封控 小区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>明康汇的采购员你成功地把你们老板一个月来的光辉形象給黑了。@明康汇 @市场监管 @江丄孤舟 ...</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>2022-04-21 08:54:29</td>\n",
       "      <td>1000074972</td>\n",
       "      <td>明康汇 的 采购员 你 成功 地 把 你们 老板 一个月 来 的 光辉 形象 給黑 了 。 ...</td>\n",
       "      <td>明康汇 采购员 成功 老板 一个月 光辉 形象 給黑 明康汇   市场监管   江 丄 孤 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content        date  \\\n",
       "0  #上海疫情##上海民生##就这一刻##返乡# 上海返乡潮开启，安徽、江苏和河南人最多，隔离和...  2022-04-24   \n",
       "1  #上海疫情##上海民生##上海现状# .上海的现状为什么会变成这样我忍不住地继续瞎想外行领导...  2022-04-23   \n",
       "2  #上海疫情##上海民生#      无间道，罗生门，可能本来就是人生如戏吧，是我太认真了。算...  2022-04-22   \n",
       "3        #上海民生##上海疫情##上海团长# 还是你牛逼呀，团长。开个车照送，还是封控小区。   2022-04-22   \n",
       "4  明康汇的采购员你成功地把你们老板一个月来的光辉形象給黑了。@明康汇 @市场监管 @江丄孤舟 ...  2022-04-21   \n",
       "\n",
       "                  time     user_id  \\\n",
       "0  2022-04-24 08:33:43  1000074972   \n",
       "1  2022-04-23 05:46:14  1000074972   \n",
       "2  2022-04-22 11:47:31  1000074972   \n",
       "3  2022-04-22 09:41:33  1000074972   \n",
       "4  2022-04-21 08:54:29  1000074972   \n",
       "\n",
       "                                         cut_content  \\\n",
       "0  # 上海 疫情 ## 上海 民生 ## 就 这 一刻 ## 返乡 #   上海 返乡 潮 开...   \n",
       "1  # 上海 疫情 ## 上海 民生 ## 上海 现状 #   . 上海 的 现状 为什么 会 ...   \n",
       "2  # 上海 疫情 ## 上海 民生 #             无间道 ， 罗生门 ， 可能 ...   \n",
       "3  # 上海 民生 ## 上海 疫情 ## 上海 团长 #   还是 你 牛 逼 呀 ， 团长 ...   \n",
       "4  明康汇 的 采购员 你 成功 地 把 你们 老板 一个月 来 的 光辉 形象 給黑 了 。 ...   \n",
       "\n",
       "                                                 del  \n",
       "0  疫情 民生 一刻 返乡   返乡 潮 开启 安徽 江苏 河南人 隔离 做 核酸 钱 返乡 潮...  \n",
       "1  疫情 民生 现状   现状 忍不住 瞎 想 外行 领导 内行 内行 闭嘴 同理 衍生 行业 ...  \n",
       "2  疫情 民生             无间道 罗生门 本来 人生 如戏 是我太 算了 干脆 眼...  \n",
       "3                   民生 疫情 团长   牛 逼 团长 开个 车照 送 封控 小区   \n",
       "4  明康汇 采购员 成功 老板 一个月 光辉 形象 給黑 明康汇   市场监管   江 丄 孤 ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读入数据\n",
    "group_1_del = pd.read_csv('D:\\my research\\group\\group_1\\group_1_final.csv',encoding='utf-8')\n",
    "group_1_del.columns = ['0','content','date','time','user_id','cut_content','del']\n",
    "group_1_del = group_1_del.drop(columns='0')\n",
    "group_1_del.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1084a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284773, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_1_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acd56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83de3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#完善停用词表\n",
    "new = (['顾魏','特别','越来越','好像','我要','刚刚','天天','林之校','啊啊啊','王一博','翟潇闻','真的','哈哈哈','感觉',\n",
    "       '不到','一点','呜呜','哈哈哈哈','好好','这是','时代','少年','余生','指教','本来','晚上','天天','不想'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10e779d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content        False\n",
       "date           False\n",
       "time           False\n",
       "user_id        False\n",
       "cut_content    False\n",
       "del             True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_1_del.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f4925f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284267, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按行删除：存在空值，即删除该行\n",
    "un = group_1_del.dropna(axis=0, how='any')\n",
    "un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a6cee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content        False\n",
       "date           False\n",
       "time           False\n",
       "user_id        False\n",
       "cut_content    False\n",
       "del            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "543af3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = []\n",
    "for line in un['del']:\n",
    "    line_u = ' '.join(str(line).split())\n",
    "    line_uu = line_u.split()#将一个元素按空格拆分成多个元素\n",
    "    outstr = ''\n",
    "    for words in line_uu:\n",
    "        if words not in new:\n",
    "            #if words in ['n','v','a','r','i']:\n",
    "                outstr += words\n",
    "                outstr += \" \"\n",
    "    aaa.append(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d00c0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造 TF-IDF\n",
    "#tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_vectorizer = TfidfVectorizer(min_df = 0.001,max_df = 0.8)\n",
    "tf_idf = tf_idf_vectorizer.fit_transform(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8dfeee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        一下子  一个个  一个多月       一个月   一人   一件   一份   一会  一会儿   一位  ...   高价   高考  \\\n",
      "0       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4       0.0  0.0   0.0  0.544491  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "...     ...  ...   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "284262  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "284263  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "284264  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "284265  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "284266  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "         魔幻   鸡蛋   麻烦   黄瓜   默默   鼓励   鼻子   龚俊  \n",
      "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "284262  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "284263  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "284264  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "284265  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "284266  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[284267 rows x 1556 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>一下子</th>\n",
       "      <th>一个个</th>\n",
       "      <th>一个多月</th>\n",
       "      <th>一个月</th>\n",
       "      <th>一人</th>\n",
       "      <th>一件</th>\n",
       "      <th>一份</th>\n",
       "      <th>一会</th>\n",
       "      <th>一会儿</th>\n",
       "      <th>一位</th>\n",
       "      <th>...</th>\n",
       "      <th>高价</th>\n",
       "      <th>高考</th>\n",
       "      <th>魔幻</th>\n",
       "      <th>鸡蛋</th>\n",
       "      <th>麻烦</th>\n",
       "      <th>黄瓜</th>\n",
       "      <th>默默</th>\n",
       "      <th>鼓励</th>\n",
       "      <th>鼻子</th>\n",
       "      <th>龚俊</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284264</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284267 rows × 1556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        一下子  一个个  一个多月       一个月   一人   一件   一份   一会  一会儿   一位  ...   高价   高考  \\\n",
       "0       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3       0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4       0.0  0.0   0.0  0.544491  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...     ...  ...   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "284262  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "284263  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "284264  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "284265  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "284266  0.0  0.0   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "         魔幻   鸡蛋   麻烦   黄瓜   默默   鼓励   鼻子   龚俊  \n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "284262  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "284263  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "284264  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "284265  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "284266  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[284267 rows x 1556 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征词列表\n",
    "feature_names = tf_idf_vectorizer.get_feature_names()\n",
    "# 特征词 TF-IDF 矩阵\n",
    "matrix = tf_idf.toarray()\n",
    "feature_names_df = pd.DataFrame(matrix,columns=feature_names)\n",
    "print(feature_names_df)\n",
    "feature_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16e16dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=50, n_components=6, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定 lda 主题数\n",
    "n_topics = 6\n",
    "# 要输出的每个主题的前 n_top_words 个主题词数\n",
    "n_top_words = 20\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics, max_iter=50,\n",
    "    learning_method='online',\n",
    "    learning_offset=50.,\n",
    "    random_state=0)\n",
    "# 核心，给 LDA 喂生成的 TF-IDF 矩阵\n",
    "lda.fit(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7e2b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_data_frame(model: LatentDirichletAllocation,\n",
    "                         tf_idf_vectorizer: TfidfVectorizer,\n",
    "                         n_top_words: int) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出每个主题的前 n_top_words 个词\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    tf_idf_vectorizer : sklearn 的 TfidfVectorizer\n",
    "    n_top_words :前 n_top_words 个主题词\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    rows = []\n",
    "    feature_names = tf_idf_vectorizer.get_feature_names()\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i]\n",
    "                     for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        rows.append(top_words)\n",
    "    columns = [f'topic {i+1}' for i in range(n_top_words)]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def predict_to_data_frame(model: LatentDirichletAllocation, X: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出文档主题概率分布情况\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    X : 词向量矩阵\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    # 求出给定文档的主题概率分布矩阵\n",
    "    matrix = model.transform(X)\n",
    "    columns = [f'P(topic {i+1})' for i in range(len(model.components_))]\n",
    "    df = pd.DataFrame(matrix, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e38b4a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(topic 1)</th>\n",
       "      <th>P(topic 2)</th>\n",
       "      <th>P(topic 3)</th>\n",
       "      <th>P(topic 4)</th>\n",
       "      <th>P(topic 5)</th>\n",
       "      <th>P(topic 6)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.238608</td>\n",
       "      <td>0.103781</td>\n",
       "      <td>0.526083</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.043855</td>\n",
       "      <td>0.043805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.241819</td>\n",
       "      <td>0.579951</td>\n",
       "      <td>0.044544</td>\n",
       "      <td>0.044547</td>\n",
       "      <td>0.044601</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.229953</td>\n",
       "      <td>0.047663</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.047031</td>\n",
       "      <td>0.047127</td>\n",
       "      <td>0.581277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.439222</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.057091</td>\n",
       "      <td>0.057837</td>\n",
       "      <td>0.057239</td>\n",
       "      <td>0.331166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061208</td>\n",
       "      <td>0.694483</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.061077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284262</th>\n",
       "      <td>0.618165</td>\n",
       "      <td>0.151378</td>\n",
       "      <td>0.104857</td>\n",
       "      <td>0.033257</td>\n",
       "      <td>0.033349</td>\n",
       "      <td>0.058994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284263</th>\n",
       "      <td>0.549691</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>0.107761</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.057769</td>\n",
       "      <td>0.027828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284264</th>\n",
       "      <td>0.595831</td>\n",
       "      <td>0.053068</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.051089</td>\n",
       "      <td>0.241185</td>\n",
       "      <td>0.029436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284265</th>\n",
       "      <td>0.619227</td>\n",
       "      <td>0.032737</td>\n",
       "      <td>0.032565</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.212417</td>\n",
       "      <td>0.070247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284266</th>\n",
       "      <td>0.634474</td>\n",
       "      <td>0.056170</td>\n",
       "      <td>0.028206</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>0.196005</td>\n",
       "      <td>0.028187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284267 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        P(topic 1)  P(topic 2)  P(topic 3)  P(topic 4)  P(topic 5)  P(topic 6)\n",
       "0         0.238608    0.103781    0.526083    0.043869    0.043855    0.043805\n",
       "1         0.241819    0.579951    0.044544    0.044547    0.044601    0.044539\n",
       "2         0.229953    0.047663    0.046950    0.047031    0.047127    0.581277\n",
       "3         0.439222    0.057445    0.057091    0.057837    0.057239    0.331166\n",
       "4         0.061208    0.694483    0.061077    0.061077    0.061077    0.061077\n",
       "...            ...         ...         ...         ...         ...         ...\n",
       "284262    0.618165    0.151378    0.104857    0.033257    0.033349    0.058994\n",
       "284263    0.549691    0.229219    0.107761    0.027731    0.057769    0.027828\n",
       "284264    0.595831    0.053068    0.029391    0.051089    0.241185    0.029436\n",
       "284265    0.619227    0.032737    0.032565    0.032807    0.212417    0.070247\n",
       "284266    0.634474    0.056170    0.028206    0.056959    0.196005    0.028187\n",
       "\n",
       "[284267 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算 n_top_words 个主题词\n",
    "top_words_df = top_words_data_frame(lda, tf_idf_vectorizer, n_top_words)\n",
    "top_words_df\n",
    "# 保存 n_top_words 个主题词到 csv 文件中\n",
    "#top_words_df.to_csv(top_words_csv_path, encoding='utf-8-sig', index=None)\n",
    "\n",
    "# 转 tf_idf 为数组，以便后面使用它来对文本主题概率分布进行计算\n",
    "X = tf_idf.toarray()\n",
    "\n",
    "# 计算完毕主题概率分布情况\n",
    "predict_df = predict_to_data_frame(lda, X)\n",
    "predict_df\n",
    "# 保存文本主题概率分布到 csv 文件中\n",
    "#predict_df.to_csv(predict_topic_csv_path, encoding='utf-8-sig', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3da80e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe9eca2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(\"Either 'corpus' with 'dictionary' or 'texts' should be provided for %s coherence.\", 'u_mass')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3460/2362835810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'u_mass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv_tmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\anaconda\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, topics, texts, corpus, dictionary, window_size, keyed_vectors, coherence, topn, processes)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    199\u001b[0m                     \u001b[1;34m\"Either 'corpus' with 'dictionary' or 'texts' should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                     \"be provided for %s coherence.\", coherence)\n",
      "\u001b[1;31mValueError\u001b[0m: (\"Either 'corpus' with 'dictionary' or 'texts' should be provided for %s coherence.\", 'u_mass')"
     ]
    }
   ],
   "source": [
    "cv_tmp = CoherenceModel(model=lda, corpus=tf_idf, dictionary=feature_names, coherence='u_mass')\n",
    "cv_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a0be6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\anaconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:228: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info  = pd.DataFrame({'saliency': saliency, 'Term': vocab, \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Oct/2022 21:06:03] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Oct/2022 21:06:04] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Oct/2022 21:08:02] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Oct/2022 21:08:02] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Oct/2022 21:08:02] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "data = pyLDAvis.sklearn.prepare(lda, tf_idf, tf_idf_vectorizer)\n",
    "#让可视化可以在notebook内显示\n",
    "pyLDAvis.show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea2f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
