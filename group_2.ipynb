{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2736db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f628e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    " \n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    " \n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95559c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cut_content</th>\n",
       "      <th>del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#上海民生##上海疫情##核酸#检测《上海人核酸“续命”尴尬：缺管子、乱加码、排队最长3小时...</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>2022-06-02 13:22:28</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 民生 ## 上海 疫情 ## 核酸 # 检测 《 上海 人 核酸 “ 续命 ” 尴...</td>\n",
       "      <td>民生 疫情 核酸 检测 核酸 续命 尴尬 缺 管子 乱 加码 排队 最长 小时 核酸 续命 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#上海民生##上海疫情##上海复工#上海醒来，6月1号不会是哄孩子的吧。6月1日零时起 上海...</td>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>2022-05-30 19:42:39</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 民生 ## 上海 疫情 ## 上海 复工 # 上海 醒来 ， 6 月 1 号 不会...</td>\n",
       "      <td>民生 疫情 复工 醒来 月 号 哄 孩子 月 日 零时   有序 恢复 住宅小区 出入 公共...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#上海民生##上海疫情# 有关团长《独家｜起底“团长江湖”：平价被抵制、供应商“强制”加价、...</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>2022-05-16 09:38:37</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 民生 ## 上海 疫情 #   有关 团长 《 独家 ｜ 起底 “ 团长 江湖 ”...</td>\n",
       "      <td>民生 疫情   团长 独家 起底 团长 江湖 平价 抵制 供应商 强制 加价 黑白 团长 大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#居委会##上海民生##上海疫情# 上海奇葩居委干部，假借抗疫强索私吞翡翠，官方属实》一个居...</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>2022-05-07 23:39:52</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 居委会 ## 上海 民生 ## 上海 疫情 #   上海 奇葩 居委 干部 ， 假借 抗...</td>\n",
       "      <td>居委会 民生 疫情   奇葩 居委 干部 假借 抗疫 强索 私吞 翡翠 官方 属实 居委 干...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#上海民生##上海疫情# 祝贺🎉五一劳动节，迎接双满月，你劳动了吗？</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>2022-05-01 17:34:27</td>\n",
       "      <td>1000074972</td>\n",
       "      <td># 上海 民生 ## 上海 疫情 #   祝贺 🎉 五一劳动节 ， 迎接 双 满月 ， 你 ...</td>\n",
       "      <td>民生 疫情   祝贺  五一劳动节 迎接 双 满月 劳动</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content        date  \\\n",
       "0  #上海民生##上海疫情##核酸#检测《上海人核酸“续命”尴尬：缺管子、乱加码、排队最长3小时...  2022-06-02   \n",
       "1  #上海民生##上海疫情##上海复工#上海醒来，6月1号不会是哄孩子的吧。6月1日零时起 上海...  2022-05-30   \n",
       "2  #上海民生##上海疫情# 有关团长《独家｜起底“团长江湖”：平价被抵制、供应商“强制”加价、...  2022-05-16   \n",
       "3  #居委会##上海民生##上海疫情# 上海奇葩居委干部，假借抗疫强索私吞翡翠，官方属实》一个居...  2022-05-07   \n",
       "4                #上海民生##上海疫情# 祝贺🎉五一劳动节，迎接双满月，你劳动了吗？   2022-05-01   \n",
       "\n",
       "                  time     user_id  \\\n",
       "0  2022-06-02 13:22:28  1000074972   \n",
       "1  2022-05-30 19:42:39  1000074972   \n",
       "2  2022-05-16 09:38:37  1000074972   \n",
       "3  2022-05-07 23:39:52  1000074972   \n",
       "4  2022-05-01 17:34:27  1000074972   \n",
       "\n",
       "                                         cut_content  \\\n",
       "0  # 上海 民生 ## 上海 疫情 ## 核酸 # 检测 《 上海 人 核酸 “ 续命 ” 尴...   \n",
       "1  # 上海 民生 ## 上海 疫情 ## 上海 复工 # 上海 醒来 ， 6 月 1 号 不会...   \n",
       "2  # 上海 民生 ## 上海 疫情 #   有关 团长 《 独家 ｜ 起底 “ 团长 江湖 ”...   \n",
       "3  # 居委会 ## 上海 民生 ## 上海 疫情 #   上海 奇葩 居委 干部 ， 假借 抗...   \n",
       "4  # 上海 民生 ## 上海 疫情 #   祝贺 🎉 五一劳动节 ， 迎接 双 满月 ， 你 ...   \n",
       "\n",
       "                                                 del  \n",
       "0  民生 疫情 核酸 检测 核酸 续命 尴尬 缺 管子 乱 加码 排队 最长 小时 核酸 续命 ...  \n",
       "1  民生 疫情 复工 醒来 月 号 哄 孩子 月 日 零时   有序 恢复 住宅小区 出入 公共...  \n",
       "2  民生 疫情   团长 独家 起底 团长 江湖 平价 抵制 供应商 强制 加价 黑白 团长 大...  \n",
       "3  居委会 民生 疫情   奇葩 居委 干部 假借 抗疫 强索 私吞 翡翠 官方 属实 居委 干...  \n",
       "4                      民生 疫情   祝贺  五一劳动节 迎接 双 满月 劳动   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读入数据\n",
    "group_2_del = pd.read_csv('D:\\my_research\\gensim_group\\group_2\\group_2_final.csv',encoding='utf-8')\n",
    "group_2_del.columns = ['0','content','date','time','user_id','cut_content','del']\n",
    "group_2_del = group_2_del.drop(columns='0')\n",
    "group_2_del = group_2_del.dropna(axis=0, how='any')\n",
    "group_2_del.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5521abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7335d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#完善停用词表\n",
    "#new = (['顾魏','特别','越来越','好像','我要','刚刚','天天','林之校','啊啊啊','王一博','翟潇闻','真的','哈哈哈','感觉',\n",
    "#       '不到','一点','呜呜','哈哈哈哈','好好','这是','时代','少年','余生','指教','本来','晚上','天天','不想','玖',\n",
    "#        '团肖战','代言人','马嘉祺','尹浩宇','热巴','迪丽','刘宇宁','摩登','兄弟','周杰伦','新歌','余宇涵','原创',\n",
    "#       '哔哩','.','两个','左航','周边','一善','太','岁','之恋','舞台','诶','好帅','好好看','生日快乐','美美',\n",
    "#       '卧槽','演唱会','一条','歌','救命','救','想','吃','做','说','月','买','天','号','明天','小时','分钟','夜',\n",
    "#       '穿','忘','祝','面','甜','咸','日','团','菜','愿','挺','明明','加','行','再也','不知','玩','挂','正','刷',\n",
    "#        '真','有没有','写','打卡','越','站','走','画','风','路','想到','回','王','心','话','掉','搞','干',\n",
    "#        '个头','  ','包','跳','图','份','开','字','咯','长','草','新','品牌','请','剧','哥哥','块','这部','超',\n",
    "#       '破','超话','祝','那种','%','服','周','店','圈','哒','语','高','页','一只','刘','名','度','达','也许',\n",
    "#       '综艺','先','亿','倒','水','元','拉','黑','宋亚轩','姐姐','嗨','受','录','秒','戏','俩','只会','手','焕新','聚力',\n",
    "#       '耀','荣耀','大会','视界','滚','假','气','派','中','少','视界','杨','女团','至少','额','算是','花','再也','帅',\n",
    "#        '生','之间','确实','耶','头','丢','易','烊','千玺','热','搜','道','灿烂','星汉','邓紫棋','棒','称','沉香',\n",
    "#       '如屑','集','毛','算',' ',' ','|','|','点','年','里','微光','喵','徐坤','亖','  '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6c1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub(r\"(回复)?(//)?\\s*@\\S*?\\s*(:| |$)\", \" \", text)  # 去除正文中的@和回复/转发中的用户名\n",
    "    text = re.sub(r\"\\[\\S+\\]\", \"\", text)      # 去除表情符号\n",
    "    text = re.sub(r\"#\\S+#\", \"\", text)      # 保留话题内容\n",
    "    URL_REGEX = re.compile(\n",
    "        r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))',\n",
    "        re.IGNORECASE)\n",
    "    text = re.sub(URL_REGEX, \"\", text)       # 去除网址\n",
    "    text = text.replace('转发微博','') # 去除无意义的词语\n",
    "    text = text.replace('网页链接','')\n",
    "    text = text.replace('的微博视频','')\n",
    "    text = text.replace('妞妞端午花草','')\n",
    "    text = text.replace('bluepoint2006','')\n",
    "    text = text.replace('上海','')\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # 合并正文中过多的空格\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91771c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for i in group_2_del['content']:\n",
    "    line_u = str(i)\n",
    "    line_uu = clean(line_u)\n",
    "    count.append(line_uu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be82095",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list ( filter ( None , count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a85db6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172083"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6646a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list1=res\n",
    "list2=[]\n",
    "for i in list1:\n",
    "    if i not in list2:\n",
    "        list2.append(i)\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8713b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169740"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c464b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a649d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(x):\n",
    "    return (word for word, flag in pseg.cut(x) if flag in ['n'])#副词\n",
    "\n",
    "texts = [cut(a) for a in list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ccfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list ( filter ( None ,texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c23b670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aaa = []\n",
    "#for line in group_2_del['del']:\n",
    "#    line_uu = re.sub('[^\\u4e00-\\u9fa5]+', '',line)\n",
    "#    line_u = cut(line_uu)\n",
    "    #line_u = ' '.join(str(line_uu).split())\n",
    "#    line = str(line_u).split()#将一个元素按空格拆分成多个元素\n",
    "#    outstr = []\n",
    "#    for words in line:\n",
    "#        if words not in new:\n",
    "            #if words in ['n','v','a','r','i']:\n",
    "#                outstr.append(words)\n",
    "#    aaa.append(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1409b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103222dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b99e5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2022-12-07 21:58:45,971 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Administrator\\AppData\\Local\\Temp\\jieba.cache\n",
      "2022-12-07 21:58:45,982 : DEBUG : Loading model from cache C:\\Users\\Administrator\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.119 seconds.\n",
      "2022-12-07 21:58:47,101 : DEBUG : Loading model cost 1.119 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2022-12-07 21:58:47,111 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(text)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.8, keep_n=None)\n",
    "corpus = [dictionary.doc2bow(tmp) for tmp in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28fb46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\anaconda\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  numerator = (co_occur_count / num_docs) + EPSILON\n",
      "D:\\Program_Files\\anaconda\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:203: RuntimeWarning: invalid value encountered in true_divide\n",
      "  denominator = (w_prime_count / num_docs) * (w_star_count / num_docs)\n",
      "D:\\Program_Files\\anaconda\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_doc_prob = co_occur_count / num_docs\n"
     ]
    }
   ],
   "source": [
    "# 困惑度的XY坐标\n",
    "x_perplexity = [] \n",
    "y_perplexity = [] \n",
    "# 一致性的XY坐标\n",
    "x_coherence = [] \n",
    "y_coherence = [] \n",
    "#id2word：就是上边构造的dictionary字典\n",
    "#passes：模型的训练次数\n",
    "for i in range(1, 31):     \n",
    "    # 循环生成主题数为i的模型， passes代表模型训练次数，数据量太大了，搞小一点。     \n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus_tfidf, num_topics=i, id2word=dictionary, passes=10)     \n",
    "    # 计算当前模型困惑度\n",
    "    cur_perplexity = lda.log_perplexity(corpus_tfidf)     \n",
    "    # 构造横纵坐标轴数据\n",
    "    x_perplexity.append(i)\n",
    "    y_perplexity.append(cur_perplexity) \n",
    "    # 计算一致性\n",
    "    cv_tmp = CoherenceModel(model=lda, texts=text, dictionary=dictionary, coherence='c_v') \n",
    "    x_coherence.append(i) \n",
    "    y_coherence.append(cv_tmp.get_coherence()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制一致性折线图 \n",
    "plt.plot(x_coherence, y_coherence) \n",
    "plt.xlabel('num topics') \n",
    "plt.ylabel('coherence score') \n",
    "plt.legend(('coherence_values'), loc='best') \n",
    "plt.savefig('D:\\my_research\\gensim_group\\new_coherenceLine_2.jpg') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen = pd.DataFrame(y_coherence, x_coherence)\n",
    "cohen.to_csv('D:\\my_research\\gensim_group\\group_coherence_2.csv',encoding=\"utf-8_sig\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp =  pd.DataFrame(y_perplexity, x_perplexity)\n",
    "perp.to_csv('D:\\my research\\gensim_group_group_perplexity_2.csv',encoding=\"utf-8_sig\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda = gensim.models.ldamodel.LdaModel(corpus_tfidf, num_topics=7, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_topics = gensim.models.ldamodel.LdaModel.top_topics(lda,corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda = gensim.models.ldamodel.LdaModel(corpus_tfidf, num_topics=6, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127a449",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pyLDAvis.enable_notebook()\n",
    "#data = pyLDAvis.gensim.prepare(lda, corpus_tfidf, dictionary)\n",
    "#让可视化可以在notebook内显示\n",
    "#pyLDAvis.show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cca56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
